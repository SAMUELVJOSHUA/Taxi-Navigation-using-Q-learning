{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MONITORING.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3OEeMDn1-Rm"
      },
      "outputs": [],
      "source": [
        "# Importing all necessaries\n",
        "from collections import deque\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# We look to store the rwds and the best of them that we obtain per 100 eps in a dataframe\n",
        "# This refers to a labelled tabular representation\n",
        "\n",
        "def save_rwds_csv(avg_rwd_100, best_avg_rwd_100):\n",
        "    eps = np.arange(1, len(avg_rwd_100) + 1)\n",
        "    rwd_per_eps = pd.DataFrame({\n",
        "        'avg_rwd_100': avg_rwd_100,\n",
        "        'best_avg_rwd_100': best_avg_rwd_100,\n",
        "        'eps': eps\n",
        "    })\n",
        "\n",
        "# Dataframe is then converted to csv for analysis    \n",
        "    rwd_per_eps.to_csv('rwds_plot_data.csv')\n",
        "\n",
        "# Interact function is defined\n",
        "# This is to monitor the performance of the agent\n",
        "# There are certain parameters regarding monitoring the performance\n",
        "# env denoting instance of the environment\n",
        "#agent dentoing instance of class Agent that was created\n",
        "#num_eps denoting number of eps of agent-environment interacn\n",
        "#window representing the number of eps to be considered for mamnipulating average rwds\n",
        "\n",
        "def interact(env, agent, num_eps=50000, window=100):\n",
        "    \n",
        "    # we initialize average rwds\n",
        "    avg_rwd_100 = []\n",
        "    best_avg_rwd_100 = []\n",
        "    avg_rwds = deque(maxlen=num_eps)\n",
        "    # we initialize best average rwd\n",
        "    best_avg_rwd = -math.inf\n",
        "    # then we initialize monitor \n",
        "    # for most recent rwds\n",
        "    sample_rwd = deque(maxlen=window)\n",
        "    \n",
        "    \n",
        "    # For each episode we run:\n",
        "    for i_episode in range(1, num_eps+1):\n",
        "        state = env.reset()\n",
        "        # initializing the sampled rwd\n",
        "        sample_rwd = 0\n",
        "        while True:\n",
        "            # agent selects an acn(action)\n",
        "            # agent then is set to perform the selected acn(action)\n",
        "            acn = agent.select_acn(state)\n",
        "            nxt_st, rwd, done, _ = env.step(acn)\n",
        "\n",
        "            # updating the sampled rwd\n",
        "            agent.step(state, acn, rwd, nxt_st, done)\n",
        "            sample_rwd += rwd\n",
        "            # updating the state to next time step\n",
        "            state = nxt_st\n",
        "            agent.update_epsilon()\n",
        "            if done:\n",
        "                sample_rwds.append(sample_rwd)\n",
        "                break\n",
        "\n",
        "# we want to get average rwd from last 100 eps and update the sampled rwd\n",
        "        if (i_episode >= 100):\n",
        "            avg_rwd = np.mean(sample_rwds)\n",
        "            avg_rwds.append(avg_rwd)\n",
        "           \n",
        "            print('episode average rwd {}'.format(avg_rwd))\n",
        "            avg_rwd_100.append(avg_rwd)\n",
        "            best_avg_rwd_100.append(best_avg_rwd)\n",
        "            if avg_rwd > best_avg_rwd:\n",
        "                best_avg_rwd = avg_rwd\n",
        "                \n",
        "        # print out progress in related to average rwd obtained\n",
        "        print(\"\\rEpisode {}/{} || Best average rwd {} || eps {} \".format(i_episode, num_eps, best_avg_rwd, agent.epsilon), end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "        # saving the best onbtained rwd to the csv we have already created\n",
        "        # and end execution after average rwds and best of them are obtained and gathered\n",
        "        if best_avg_rwd >= 9.7:\n",
        "            print('\\nEnvironment solved in {} eps.'.format(i_episode), end=\"\")\n",
        "            agent.q_table.save(best_avg_rwd)\n",
        "            save_rwds_csv(avg_rwd_100, best_avg_rwd_100)\n",
        "            break\n",
        "        if i_episode == num_eps: \n",
        "            agent.q_table.save(best_avg_rwd)\n",
        "            save_rwds_csv(avg_rwd_100, best_avg_rwd_100)\n",
        "            print('\\n')\n",
        "    return avg_rwds, best_avg_rwd"
      ]
    }
  ]
}